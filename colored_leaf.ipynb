{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import os\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "np.random.seed(1) \n",
    "tf.set_random_seed(1)\n",
    "\n",
    "num_train_imgs = 1500 # number of training images         \n",
    "original_img_directory = '/home/mele/datasets/plant_deases/color/'\n",
    "resized_img_directory = 'img_resizesd/'\n",
    "\n",
    "pre_train_epochs = 1 # num of epochs to pre-train discrimitor\n",
    "training_epochs = 20001 # num of epochs to train discriminator and generator jointly\n",
    "batch_size = 64 # batch size for training the model, must be larger than batch_size_sample\n",
    "\n",
    "# for the generated images\n",
    "batch_size_sample = 36 # number of images to be generated for viewing the training progress\n",
    "# the generated images will be concatenated, the product of the following must equal to batch_size_sample\n",
    "sample_num_rows = 6 # how many rows to have\n",
    "sample_num_columns = 6 # how many columns to have\n",
    "\n",
    "leak = 0.2 # degree of leakiness used in leaky ReLU\n",
    "alpha = 0.0002 # base learning rate\n",
    "beta1 = 0.5 # the fraction factor used in the first momentum term from Adam optimizer\n",
    "k = 1 # this is number of times to update generator for every time discriminator is updated in each epoch\n",
    "logs_path = \"./dcgan_leaf_log\" # directory to save the training log to\n",
    "train_sample_directory = './dcgan_leaf/train_sample/' # directory to save the generated images during training\n",
    "model_directory = './dcgan_leaf/models' # directory to save trained model\n",
    "sample_directory = './dcgan_leaf/generated_sample/' # directory to save the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess by resizing them.\n",
    "\n",
    "# # get a list of image filenames\n",
    "# for a_dir in os.listdir(original_img_directory):\n",
    "#     file_names = [f for f in os.listdir(original_img_directory+'/'+a_dir)[:100+1] if f.endswith('.JPG')]\n",
    "\n",
    "#     # get a list of images\n",
    "#     images = []\n",
    "#     for f in file_names:\n",
    "#         img = Image.open(original_img_directory+'/'+a_dir +'/'+f)\n",
    "#         images.append(img.copy())\n",
    "#         img.close() \n",
    "\n",
    "#     if not os.path.exists(resized_img_directory):\n",
    "#         os.makedirs(resized_img_directory)\n",
    "\n",
    "#     # save the resized images\n",
    "#     for i,img in enumerate(images):\n",
    "#         img = resizeimage.resize_contain(img, [64, 64]) # resize the image from 178*218 to 64*64\n",
    "#         img.save(resized_img_directory+'/'+file_names[i], img.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del images # remove images variable to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read training images\n",
    "\n",
    "# get a list of image filenames\n",
    "for a_dir in os.listdir(original_img_directory):\n",
    "    file_names = [f for f in os.listdir(original_img_directory+'/'+a_dir)[:1000+1] if f.endswith('.JPG')]\n",
    "\n",
    "    images = []\n",
    "    for f in file_names:\n",
    "        img = Image.open(original_img_directory+'/'+a_dir +'/'+f)\n",
    "        images.append(img.copy())\n",
    "        #img.close() \n",
    "\n",
    "    # turn image into ndarray\n",
    "    train_images = np.array([np.asarray(img) for img in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "#This function performns a leaky relu activation, which is needed for the discriminator network.\n",
    "def leaky_relu(x, leak=leak, name=\"leaky_relu\"):\n",
    "    with tf.variable_scope(name):\n",
    "        return tf.maximum(leak*x, x)\n",
    "\n",
    "# get a batch of real images, change size from 28*28 to 32*32, return the processed batch\n",
    "def get_x(batch_size):\n",
    "    indices = np.random.randint(num_train_imgs, size=batch_size) # random sample real images\n",
    "    batch = train_images[indices] \n",
    "    batch = 2*(batch/255.)-1 # change range from [0, 255] to [-1, 1]\n",
    "    return batch\n",
    "\n",
    "# wrapper function for real images\n",
    "def save_real_images(images, size, image_path):\n",
    "    concat_img = concat(images, size) # concatenate individual images to a grid of images\n",
    "    concat_img = Image.fromarray(concat_img) # convert ndarray to an image object\n",
    "    concat_img.save(image_path, 'PNG')\n",
    "\n",
    "# wrapper function for generated images\n",
    "def save_generated_images(images, size, image_path):\n",
    "    images = inverse_transform(images)\n",
    "    concat_img = concat(images, size) # concatenate individual images to a grid of images\n",
    "    concat_img = Image.fromarray(concat_img) # convert ndarray to an image object\n",
    "    concat_img.save(image_path, 'PNG')\n",
    "\n",
    "# change values from [-1, 1] to [0, 255]\n",
    "def inverse_transform(images):\n",
    "    return (images+1.)/2. * 255\n",
    "\n",
    "# concatenate individual images to a grid of images\n",
    "def concat(images, size):\n",
    "    # get height and width for a single image generated, e.g. 64 * 64\n",
    "    height, width = images.shape[1], images.shape[2] \n",
    "    \n",
    "    # placeholder for a concatenated img, which have \n",
    "    # img_height = image height * num images vertically, e.g. 64 * 5\n",
    "    # img_width = image width * num images horizontally, e.g. 64 * 5\n",
    "    img = np.zeros((height * size[0], width * size[1],3)) \n",
    "\n",
    "    # loop through each image\n",
    "    for index, image in enumerate(images):\n",
    "        j = index / size[0] # image row index\n",
    "        i = index % size[1] # image column index\n",
    "        img[j*height:j*height+height, i*width:i*width+width,:] = image\n",
    "\n",
    "    return img.astype(np.uint8) # convert ndarray to uint8 type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(train_sample_directory):\n",
    "#     os.makedirs(train_sample_directory)\n",
    "\n",
    "# indices = np.random.randint(num_train_imgs, size=batch_size_sample) # random sample real images\n",
    "# batch = train_images[indices] # with shape [batch,64,64,3]\n",
    "# save_real_images(images=batch, size=[sample_num_rows,sample_num_columns], image_path=train_sample_directory+'/fig_original.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator network takes a noise vector z and return a 64 * 64 image. \n",
    "def generator(z, reuse=False, is_train=True):\n",
    "    \n",
    "    # Turn z into the first tensor + batch norm + relu\n",
    "    # Creates a fully connected weight matrix, which is multiplied by the mini-batch of z vectors to \n",
    "    # produce a hidden layer with 4*4*1024 hidden nodes\n",
    "    zP = slim.fully_connected(inputs=z,num_outputs=4*4*1024,normalizer_fn=slim.batch_norm, normalizer_params={\"is_training\":is_train},\\\n",
    "        reuse=reuse,activation_fn=tf.nn.relu,scope='g_init',weights_initializer=initializer)\n",
    "    # Transform the flat 4*4*1024 layer into a tensor, whose kernel size is 4*4 and 512 kernels in total\n",
    "    # -1 stands for the mini-batch size that's to be computed\n",
    "    zCon = tf.reshape(zP,[-1,4,4,1024])\n",
    "    \n",
    "    # Perform fractionally-strided convolution/deconvolution + batch norm + relu\n",
    "    # num_outputs: number of output filters/activation maps\n",
    "    # kernel_size: [kernel_height, kernel_width]\n",
    "    # stride: [stride_height, stride_width], in this case it is generating four pixels out of every pixel, this gives fractionally-strided convolution\n",
    "    # output size batch_size*8*8*512\n",
    "    gen1 = slim.convolution2d_transpose(\\\n",
    "        inputs=zCon,num_outputs=512,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm, normalizer_params={\"is_training\":is_train},\\\n",
    "        reuse=reuse,activation_fn=tf.nn.relu,scope='g_conv1', weights_initializer=initializer)\n",
    "    \n",
    "    # output size batch_size*16*16*256\n",
    "    gen2 = slim.convolution2d_transpose(\\\n",
    "        inputs=gen1,num_outputs=256,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm, normalizer_params={\"is_training\":is_train},\\\n",
    "        reuse=reuse,activation_fn=tf.nn.relu,scope='g_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    # output size batch_size*32*32*128\n",
    "    gen3 = slim.convolution2d_transpose(\\\n",
    "        inputs=gen2,num_outputs=128,kernel_size=[5,5],stride=[2,2],\\\n",
    "        padding=\"SAME\",normalizer_fn=slim.batch_norm, normalizer_params={\"is_training\":is_train},\\\n",
    "        reuse=reuse,activation_fn=tf.nn.relu,scope='g_conv3', weights_initializer=initializer)\n",
    "    \n",
    "    # output size batch_size*64*64*3\n",
    "    g_out = slim.convolution2d_transpose(\\\n",
    "        inputs=gen3,num_outputs=3,kernel_size=[5,5],stride=[2,2],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=tf.nn.tanh,\\\n",
    "        reuse=reuse,scope='g_output', weights_initializer=initializer)\n",
    "    \n",
    "    return g_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The discriminator network takes a 64*64 image and return a probability of whether it is real or generated\n",
    "def discriminator(image, reuse=False, is_train=True):\n",
    "    # Creates 32 4*4 filters to convolve on the mini-batch of 64*64*3 images, also perform batch norm + leaky ReLU activation\n",
    "    # Note that no pooling is performed\n",
    "    # stride here calculates one pixel out of every 2*2 pixels, this gives strided convolution that will shrink the image as a substitute for pooling\n",
    "    # Set reuse=True allows discriminator to evaluate both real samples and generated samples \n",
    "    # Outputs size batch_size*32*32*32 \n",
    "    \n",
    "    dis1 = slim.convolution2d(inputs=image,num_outputs=32,kernel_size=[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "        biases_initializer=None,activation_fn=leaky_relu,\\\n",
    "        reuse=reuse,scope='d_conv1',weights_initializer=initializer)\n",
    "    \n",
    "    # outputs size batch_size*16*16*64 \n",
    "    dis2 = slim.convolution2d(inputs=dis1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm, normalizer_params={\"is_training\":is_train}, activation_fn=leaky_relu,\\\n",
    "        reuse=reuse,scope='d_conv2', weights_initializer=initializer)\n",
    "    \n",
    "    # outputs size batch_size*8*8*128 \n",
    "    dis3 = slim.convolution2d(inputs=dis2,num_outputs=128,kernel_size=[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm, normalizer_params={\"is_training\":is_train},activation_fn=leaky_relu,\\\n",
    "        reuse=reuse,scope='d_conv3',weights_initializer=initializer)\n",
    "    \n",
    "    # outputs size batch_size*4*4*256 \n",
    "    dis4 = slim.convolution2d(inputs=dis3,num_outputs=256,kernel_size=[4,4],stride=[2,2],padding=\"SAME\",\\\n",
    "        normalizer_fn=slim.batch_norm, normalizer_params={\"is_training\":is_train},activation_fn=leaky_relu,\\\n",
    "        reuse=reuse,scope='d_conv4',weights_initializer=initializer)\n",
    "\n",
    "    # flatten the tensor to [batch_size, 4*4*256]\n",
    "    dis_flat = slim.flatten(dis4)\n",
    "    \n",
    "    # create a fully connect layer with dis_flat and just one node in the output layer\n",
    "    # note there's no batch normalization at this layer\n",
    "    # outputs size batch_size*1 \n",
    "    d_out = slim.fully_connected(inputs=dis_flat,num_outputs=1,\\\n",
    "        activation_fn=tf.nn.sigmoid, reuse=reuse, scope='d_output', weights_initializer=initializer)\n",
    "    \n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable d_conv1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 246, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 291, in model_variable\n    use_resource=use_resource)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-614e0df4f1af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre_train_labels'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# feed images to the discriminator and return the predicted probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0md_pre_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0msummary_pre_d_x_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pre_train_d_prob_x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_pre_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-1b898147bc62>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(image, reuse, is_train)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Outputs size batch_size*32*32*32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdis1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolution2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SAME\"\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0mbiases_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'd_conv1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# outputs size batch_size*16*16*64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0m_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         _reuse=reuse)\n\u001b[0;32m-> 1050\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;31m# Add variables to collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    807\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \"\"\"\n\u001b[0;32m--> 809\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m               \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m           \u001b[0;31m# Note: not all sub-classes of Layer call Layer.__init__ (especially\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    141\u001b[0m                                     \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                                     \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                                     dtype=self.dtype)\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m       self.bias = self.add_variable(name='bias',\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                    \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                    \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                                    partitioner=partitioner)\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minit_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1295\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1298\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1299\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1091\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    429\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"constraint\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constraint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m       return _true_getter(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[0;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, **_)\u001b[0m\n\u001b[1;32m   1602\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m       use_resource=use_resource)\n\u001b[0m\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\u001b[0m\n\u001b[1;32m    289\u001b[0m                  \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                  \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                  use_resource=use_resource)\n\u001b[0m\u001b[1;32m    292\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\u001b[0m\n\u001b[1;32m    244\u001b[0m                   \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m                   \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                   use_resource=use_resource)\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    406\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    745\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 747\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    748\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable d_conv1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 246, in variable\n    use_resource=use_resource)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 291, in model_variable\n    use_resource=use_resource)\n"
     ]
    }
   ],
   "source": [
    "z_size = 100 # size of initial noise vector that will be used for generator\n",
    "\n",
    "# initialize all parameters of the networks\n",
    "# weights were initialized from a zero-centered Normal distribution with standard deviation 0.02\n",
    "# tf.truncated_normal returns random values from a normal distribution and made sure no value exceeds 2 std\n",
    "\n",
    "initializer = tf.truncated_normal_initializer(stddev=0.02)\n",
    "\n",
    "# placeholders for inputs into the generator and discriminator, respectively.\n",
    "z_vector = tf.placeholder(shape=[batch_size,z_size],dtype=tf.float32, name='z_vectors') \n",
    "x_vector = tf.placeholder(shape=[batch_size,64,64,3],dtype=tf.float32, name='real_images') \n",
    "whether_is_train = tf.placeholder(tf.bool) # boolean variable indicating if it is in training mode or not\n",
    "\n",
    "# ---- Pre-training ----\n",
    "\n",
    "# the discriminator should output probability=1 for all the training images\n",
    "\n",
    "train_labels=tf.constant(1.0,shape=(batch_size,1), name='pre_train_labels')\n",
    "\n",
    "# feed images to the discriminator and return the predicted probability\n",
    "d_pre_output = discriminator(x_vector)                                              \n",
    "summary_pre_d_x_hist = tf.histogram_summary(\"pre_train_d_prob_x\", d_pre_output)\n",
    "\n",
    "d_pre_loss=tf.reduce_mean(tf.square(d_pre_output-train_labels))\n",
    "summary_pre_d_loss = tf.scalar_summary(\"pre_train_d_loss\", d_pre_loss)\n",
    "# ---- end of Pre-training ----\n",
    "\n",
    "\n",
    "# ---- DCGAN ----\n",
    "\n",
    "g_output = tf.cond(whether_is_train, \n",
    "                   lambda: generator(z_vector,is_train=True), \n",
    "                   lambda: generator(z_vector,reuse=True,is_train=False))# generated mini-batch of images from noisy z vectors \n",
    "#g_output = generator(z_vector,is_train) # generated mini-batch of images from noisy z vectors \n",
    "    \n",
    "d_output_x = discriminator(x_vector,reuse=True) # probabilities for real images\n",
    "d_output_x = tf.maximum(tf.minimum(d_output_x, 0.99), 0.01) # avoid inf and -inf\n",
    "summary_d_x_hist = tf.histogram_summary(\"d_prob_x\", d_output_x)\n",
    "\n",
    "d_output_z = discriminator(g_output,reuse=True) # probabilities for generated images\n",
    "d_output_z = tf.maximum(tf.minimum(d_output_z, 0.99), 0.01) # avoid inf and -inf\n",
    "# summary_d_z_hist = tf.histogram_summary(\"d_prob_z\", d_output_z)\n",
    "\n",
    "d_loss = -tf.reduce_mean(tf.log(d_output_x) + tf.log(1-d_output_z)) # loss for discriminator\n",
    "# summary_d_loss = tf.scalar_summary(\"d_loss\", d_loss)\n",
    "\n",
    "g_loss = -tf.reduce_mean(tf.log(d_output_z)) # loss for generator\n",
    "# summary_g_loss = tf.scalar_summary(\"g_loss\", g_loss)\n",
    "\n",
    "# the following parameter indices may change if the network structure changes\n",
    "para_d = tf.trainable_variables()[:9] # parameters for discriminator\n",
    "para_g = tf.trainable_variables()[9:] # parameters for generator\n",
    "\n",
    "# only update parameters in discriminator during pre-training\n",
    "pre_optimizer = tf.train.AdamOptimizer(learning_rate=alpha,beta1=beta1).minimize(d_pre_loss,var_list=para_d)\n",
    "# only update the weights for the discriminator network\n",
    "optimizer_op_d = tf.train.AdamOptimizer(learning_rate=alpha,beta1=beta1).minimize(d_loss,var_list=para_d)\n",
    "# only update the weights for the generator network\n",
    "optimizer_op_g = tf.train.AdamOptimizer(learning_rate=alpha,beta1=beta1).minimize(g_loss,var_list=para_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-12-1c02b0afa811>, line 29)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-1c02b0afa811>\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    print \"pre-train epoch: \", epoch,\", time spent: %.2fs\" % time_lapse\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# create a log folder and save the graph structure, do this before training\n",
    "g_writer = tf.train.SummaryWriter(logs_path + '/generator', graph=tf.get_default_graph())\n",
    "d_writer = tf.train.SummaryWriter(logs_path + '/discriminator')\n",
    "\n",
    "# saver saves and loads variables of the model to and from checkpoints, \n",
    "# which are binary files that maps variable names to tensor values\n",
    "saver = tf.train.Saver(max_to_keep=20) \n",
    "\n",
    "\n",
    "with tf.Session(config=config) as sess:  \n",
    "   --+ # variables need to be initialized before we can use them\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    #print [v.name for v in tf.trainable_variables()] # print all variable names\n",
    "    \n",
    "    \n",
    "    # -------- pre-train discriminator --------\n",
    "    start = time.time()\n",
    "    for epoch in range(pre_train_epochs):\n",
    "        x = get_x(batch_size) # get a batch of real images, with range [-1 ,1]\n",
    "        \n",
    "        d_pre_summary_merge = tf.merge_summary([summary_pre_d_loss, summary_pre_d_x_hist])\n",
    "        summary_pre_d,_=sess.run([d_pre_summary_merge,pre_optimizer], feed_dict={x_vector: x})\n",
    "        \n",
    "        d_writer.add_summary(summary_pre_d, epoch) # add loss summary to tensorboard\n",
    "        time_lapse = time.time()-start\n",
    "        start = time.time()\n",
    "        print \"pre-train epoch: \", epoch,\", time spent: %.2fs\" % time_lapse\n",
    "   \n",
    "    print \"pre-train done.\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # -------- jointly training discriminator and generator --------\n",
    "    start = time.time()\n",
    "    \n",
    "    # z noise vector that will be used to generate image to check the training progress\n",
    "    z_sample = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        # get a batch of real images, with range [-1 ,1]\n",
    "        x = get_x(batch_size) \n",
    "        # mini-batch of noise data from [-1, 1]\n",
    "        z = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "        \n",
    "        \n",
    "        if epoch <= 200:\n",
    "            # make a directory for generated images\n",
    "            if not os.path.exists(train_sample_directory):\n",
    "+**                os.makedirs(train_sample_directory)\n",
    "            # get a generated image, with range [-1, 1]\n",
    "            g_images = sess.run(g_output,feed_dict={z_vector:z_sample}) \n",
    "            # substitute 1/5 of the training images to the generated images, to increase discriminator's difficulty \n",
    "            substitute_indices = np.random.randint(batch_size, size=batch_size/5) \n",
    "            x[substitute_indices] = g_images[substitute_indices]\n",
    "\n",
    "        \n",
    "        # Update the discriminator\n",
    "        d_summary_merge = tf.merge_summary([summary_d_loss, summary_d_x_hist,summary_d_z_hist])\n",
    "        summary_d,_ = sess.run([d_summary_merge,optimizer_op_d],feed_dict={z_vector:z, x_vector:x}) \n",
    "        \n",
    "        \n",
    "        if epoch<20:\n",
    "            # Update the generator for k times in the specified n epoch\n",
    "            for i in range(k):\n",
    "                summary_g,_ = sess.run([summary_g_loss,optimizer_op_g],feed_dict={z_vector:z})\n",
    "        else:\n",
    "            summary_g,_ = sess.run([summary_g_loss,optimizer_op_g],feed_dict={z_vector:z})\n",
    "        \n",
    "        \n",
    "        # add loss summary to tensorboard\n",
    "        if epoch % 1 == 0:\n",
    "            d_writer.add_summary(summary_d, epoch) \n",
    "            g_writer.add_summary(summary_g, epoch)\n",
    "        \n",
    "        # output generated image\n",
    "        if epoch % 200 == 0 or epoch in [5,60,100,150]:\n",
    "            time_lapse = time.time()-start\n",
    "            start = time.time()\n",
    "            \n",
    "            print \"DCGAN epoch: \", epoch,\", time spent: %.2fs\" % time_lapse\n",
    "            g_images = sess.run(g_output,feed_dict={z_vector:z_sample}) # get a generated image, with range [-1, 1]\n",
    "            \n",
    "            # make a directory for generated images\n",
    "            if not os.path.exists(train_sample_directory):\n",
    "                os.makedirs(train_sample_directory)\n",
    "            \n",
    "            #Save sample generator images for viewing training progress.\n",
    "            save_generated_images(images = np.reshape(g_images[0:batch_size_sample],[batch_size_sample,64,64,3]),\\\n",
    "                        size = [sample_num_rows,sample_num_columns], image_path = train_sample_directory+'/'+str(epoch)+'.png')\n",
    "            \n",
    "        if epoch in [0,500,1000,2000,4000,6000,8000,10000,15000]:\n",
    "            # make a directory for trained models\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            \n",
    "            # save the trained model at different epoch\n",
    "            saver.save(sess, save_path = model_directory + '/' + str(epoch) + '.cptk')\n",
    "    print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue the model from the last check point\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'model_checkpoint_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-de5f587c2812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_checkpoint_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'model_checkpoint_path'"
     ]
    }
   ],
   "source": [
    "ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "ckpt.model_checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-15-2741f1a182f3>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-2741f1a182f3>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print 'Loading models...might take a minute'\u001b[0m\n\u001b[0m                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "print ('Loading models...might take a minute')\n",
    "saver = tf.train.Saver(max_to_keep=20)\n",
    "\n",
    "# create a log folder and save the graph structure, do this before training\n",
    "g_writer = tf.train.SummaryWriter(logs_path + '/generator', graph=tf.get_default_graph())\n",
    "d_writer = tf.train.SummaryWriter(logs_path + '/discriminator')\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "\n",
    "with tf.Session(config=config) as sess:  \n",
    "    start = time.time()\n",
    "    \n",
    "    ckpt = tf.train.get_checkpoint_state(model_directory)\n",
    "    model = ckpt.model_checkpoint_path\n",
    "\n",
    "    # z noise vector that will be used to generate image to check the training progress\n",
    "    z_sample = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "    \n",
    "    saver.restore(sess, save_path=model)\n",
    "    \n",
    "    for epoch in range(14500,training_epochs):\n",
    "        # get a batch of real images, with range [-1 ,1]\n",
    "        x = get_x(batch_size) \n",
    "        # mini-batch of noise data from [-1, 1]\n",
    "        z = np.random.uniform(-1.0,1.0,size=[batch_size,z_size]).astype(np.float32)\n",
    "        \n",
    "        # Update the discriminator\n",
    "        d_summary_merge = tf.merge_summary([summary_d_loss, summary_d_x_hist,summary_d_z_hist])\n",
    "        summary_d,_ = sess.run([d_summary_merge,optimizer_op_d],feed_dict={z_vector:z, x_vector:x}) \n",
    "        \n",
    "        # Update the generator\n",
    "        summary_g,_ = sess.run([summary_g_loss,optimizer_op_g],feed_dict={z_vector:z})\n",
    "        \n",
    "        # add loss summary to tensorboard\n",
    "        if epoch % 20 == 0:\n",
    "            d_writer.add_summary(summary_d, epoch) \n",
    "            g_writer.add_summary(summary_g, epoch)\n",
    "        \n",
    "        # output generated image\n",
    "        if epoch % 200 == 0:\n",
    "            time_lapse = time.time()-start\n",
    "            start = time.time()\n",
    "            \n",
    "            print \"DCGAN epoch: \", epoch,\", time spent: %.2fs\" % time_lapse\n",
    "            g_images = sess.run(g_output,feed_dict={z_vector:z_sample}) # get a generated image, with range [-1, 1]\n",
    "            \n",
    "            # make a directory for generated images\n",
    "            if not os.path.exists(train_sample_directory):\n",
    "                os.makedirs(train_sample_directory)\n",
    "            \n",
    "            #Save sample generator images for viewing training progress.\n",
    "            save_generated_images(images = np.reshape(g_images[0:batch_size_sample],[batch_size_sample,64,64,3]),\\\n",
    "                        size = [sample_num_rows,sample_num_columns], image_path = train_sample_directory+'/'+str(epoch)+'.png')\n",
    "            \n",
    "        if epoch in [16500,17000]:\n",
    "            # make a directory for trained models\n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            \n",
    "            # save the trained model at different epoch\n",
    "            saver.save(sess, save_path = model_directory + '/' + str(epoch) + '.cptk')\n",
    "    print (\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
